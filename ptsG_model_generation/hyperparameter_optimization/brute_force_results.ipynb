{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import dill as pickle\n",
    "import time\n",
    "\n",
    "from deap import algorithms, base, creator, tools\n",
    "\n",
    "from sympy import *\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "sys.path.append('../../promoter_solving/')\n",
    "from promoter_solving_core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'/home/gchhughes/Dropbox (UCSD SBRG)/gchughes@ucsd.edu’s files/regulonML_hyperparameter_optimization/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__seed_42__gen_100__pop_100__mu_100__lambda_100__cxind_0__cxgene_0.2__mtind_1__mtgene_0.4.pkl\n",
      "__seed_42__gen_100__pop_100__mu_100__lambda_100__cxind_0__cxgene_0.2__mtind_1__mtgene_0.6.pkl\n",
      "__seed_42__gen_100__pop_100__mu_100__lambda_100__cxind_0__cxgene_0.4__mtind_1__mtgene_0.6.pkl\n",
      "__seed_42__gen_100__pop_100__mu_100__lambda_100__cxind_0__cxgene_0.2__mtind_1__mtgene_0.2.pkl\n",
      "__seed_42__gen_100__pop_100__mu_100__lambda_100__cxind_0__cxgene_0.4__mtind_1__mtgene_0.4.pkl\n",
      "__seed_42__gen_100__pop_100__mu_100__lambda_100__cxind_0__cxgene_0.4__mtind_1__mtgene_0.8.pkl\n",
      "__seed_42__gen_100__pop_100__mu_100__lambda_100__cxind_0__cxgene_0.2__mtind_1__mtgene_1.pkl\n",
      "__seed_42__gen_100__pop_100__mu_100__lambda_100__cxind_0__cxgene_0.2__mtind_1__mtgene_0.8.pkl\n",
      "__seed_42__gen_100__pop_100__mu_100__lambda_100__cxind_0__cxgene_0.4__mtind_1__mtgene_0.2.pkl\n",
      "__seed_42__gen_100__pop_100__mu_100__lambda_100__cxind_0__cxgene_0.4__mtind_1__mtgene_1.pkl\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'seed_42',\n",
       " 'gen_100',\n",
       " 'pop_100',\n",
       " 'mu_100',\n",
       " 'lambda_100',\n",
       " 'cxind_0',\n",
       " 'cxgene_0.4',\n",
       " 'mtind_1',\n",
       " 'mtgene_1.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for filename.split('__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='__seed_42__gen_100__pop_100__mu_100__lambda_100__cxind_0__cxgene_0.2__mtind_1__mtgene_0.2.pkl', mode='rb') as file:\n",
    "    test_grid, test_pop, test_logbook, elapsed_time = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gen': 0, 'nevals': 100, 'best': 0.550929794572157},\n",
       " {'gen': 1, 'nevals': 100, 'best': 0.550929794572157},\n",
       " {'gen': 2, 'nevals': 100, 'best': 0.550929794572157},\n",
       " {'gen': 3, 'nevals': 100, 'best': 0.550929794572157},\n",
       " {'gen': 4, 'nevals': 100, 'best': 0.5797571287389252},\n",
       " {'gen': 5, 'nevals': 100, 'best': 0.5979781310426396},\n",
       " {'gen': 6, 'nevals': 100, 'best': 0.5979781310426396},\n",
       " {'gen': 7, 'nevals': 100, 'best': 0.6087586093049161},\n",
       " {'gen': 8, 'nevals': 100, 'best': 0.6250324212535664},\n",
       " {'gen': 9, 'nevals': 100, 'best': 0.6509784363838431},\n",
       " {'gen': 10, 'nevals': 100, 'best': 0.6653866225960887},\n",
       " {'gen': 11, 'nevals': 100, 'best': 0.6653866225960887},\n",
       " {'gen': 12, 'nevals': 100, 'best': 0.6653866225960887},\n",
       " {'gen': 13, 'nevals': 100, 'best': 0.6778464693299551},\n",
       " {'gen': 14, 'nevals': 100, 'best': 0.6778464693299551},\n",
       " {'gen': 15, 'nevals': 100, 'best': 0.6778464693299551},\n",
       " {'gen': 16, 'nevals': 100, 'best': 0.6778464693299551},\n",
       " {'gen': 17, 'nevals': 100, 'best': 0.7136037253900761},\n",
       " {'gen': 18, 'nevals': 100, 'best': 0.7136037253900761},\n",
       " {'gen': 19, 'nevals': 100, 'best': 0.7136037253900761},\n",
       " {'gen': 20, 'nevals': 100, 'best': 0.7136037253900761},\n",
       " {'gen': 21, 'nevals': 100, 'best': 0.717670345974911},\n",
       " {'gen': 22, 'nevals': 100, 'best': 0.7366328230975518},\n",
       " {'gen': 23, 'nevals': 100, 'best': 0.7366328230975518},\n",
       " {'gen': 24, 'nevals': 100, 'best': 0.7366328230975518},\n",
       " {'gen': 25, 'nevals': 100, 'best': 0.7648428226440126},\n",
       " {'gen': 26, 'nevals': 100, 'best': 0.7648428226440126},\n",
       " {'gen': 27, 'nevals': 100, 'best': 0.7648428226440126},\n",
       " {'gen': 28, 'nevals': 100, 'best': 0.7648428226440126},\n",
       " {'gen': 29, 'nevals': 100, 'best': 0.8067458851785603},\n",
       " {'gen': 30, 'nevals': 100, 'best': 0.8067458851785603},\n",
       " {'gen': 31, 'nevals': 100, 'best': 0.8067458851785603},\n",
       " {'gen': 32, 'nevals': 100, 'best': 0.8067458851785603},\n",
       " {'gen': 33, 'nevals': 100, 'best': 0.8067458851785603},\n",
       " {'gen': 34, 'nevals': 100, 'best': 0.8067458851785603},\n",
       " {'gen': 35, 'nevals': 100, 'best': 0.8067458851785603},\n",
       " {'gen': 36, 'nevals': 100, 'best': 0.8067458851785603},\n",
       " {'gen': 37, 'nevals': 100, 'best': 0.8401651095383027},\n",
       " {'gen': 38, 'nevals': 100, 'best': 0.8401651095383027},\n",
       " {'gen': 39, 'nevals': 100, 'best': 0.8401651095383027},\n",
       " {'gen': 40, 'nevals': 100, 'best': 0.8401651095383027},\n",
       " {'gen': 41, 'nevals': 100, 'best': 0.8401651095383027},\n",
       " {'gen': 42, 'nevals': 100, 'best': 0.8401651095383027},\n",
       " {'gen': 43, 'nevals': 100, 'best': 0.8401651095383027},\n",
       " {'gen': 44, 'nevals': 100, 'best': 0.8401651095383027},\n",
       " {'gen': 45, 'nevals': 100, 'best': 0.843643088482658},\n",
       " {'gen': 46, 'nevals': 100, 'best': 0.843643088482658},\n",
       " {'gen': 47, 'nevals': 100, 'best': 0.843643088482658},\n",
       " {'gen': 48, 'nevals': 100, 'best': 0.843643088482658},\n",
       " {'gen': 49, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 50, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 51, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 52, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 53, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 54, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 55, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 56, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 57, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 58, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 59, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 60, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 61, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 62, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 63, 'nevals': 100, 'best': 0.8506538185771196},\n",
       " {'gen': 64, 'nevals': 100, 'best': 0.8660195671487247},\n",
       " {'gen': 65, 'nevals': 100, 'best': 0.8660195671487247},\n",
       " {'gen': 66, 'nevals': 100, 'best': 0.8660195671487247},\n",
       " {'gen': 67, 'nevals': 100, 'best': 0.8660195671487247},\n",
       " {'gen': 68, 'nevals': 100, 'best': 0.8660195671487247},\n",
       " {'gen': 69, 'nevals': 100, 'best': 0.8689227986076791},\n",
       " {'gen': 70, 'nevals': 100, 'best': 0.8689227986076791},\n",
       " {'gen': 71, 'nevals': 100, 'best': 0.8689227986076791},\n",
       " {'gen': 72, 'nevals': 100, 'best': 0.8689227986076791},\n",
       " {'gen': 73, 'nevals': 100, 'best': 0.8689227986076791},\n",
       " {'gen': 74, 'nevals': 100, 'best': 0.8689227986076791},\n",
       " {'gen': 75, 'nevals': 100, 'best': 0.9002714970362103},\n",
       " {'gen': 76, 'nevals': 100, 'best': 0.9002714970362103},\n",
       " {'gen': 77, 'nevals': 100, 'best': 0.9002714970362103},\n",
       " {'gen': 78, 'nevals': 100, 'best': 0.9002714970362103},\n",
       " {'gen': 79, 'nevals': 100, 'best': 0.9002714970362103},\n",
       " {'gen': 80, 'nevals': 100, 'best': 0.9002714970362103},\n",
       " {'gen': 81, 'nevals': 100, 'best': 0.9002714970362103},\n",
       " {'gen': 82, 'nevals': 100, 'best': 0.9002714970362103},\n",
       " {'gen': 83, 'nevals': 100, 'best': 0.9002714970362103},\n",
       " {'gen': 84, 'nevals': 100, 'best': 0.9002714970362103},\n",
       " {'gen': 85, 'nevals': 100, 'best': 0.9005395970720224},\n",
       " {'gen': 86, 'nevals': 100, 'best': 0.9005395970720224},\n",
       " {'gen': 87, 'nevals': 100, 'best': 0.9005395970720224},\n",
       " {'gen': 88, 'nevals': 100, 'best': 0.9005395970720224},\n",
       " {'gen': 89, 'nevals': 100, 'best': 0.9005395970720224},\n",
       " {'gen': 90, 'nevals': 100, 'best': 0.9005395970720224},\n",
       " {'gen': 91, 'nevals': 100, 'best': 0.9005395970720224},\n",
       " {'gen': 92, 'nevals': 100, 'best': 0.9005395970720224},\n",
       " {'gen': 93, 'nevals': 100, 'best': 0.9005395970720224},\n",
       " {'gen': 94, 'nevals': 100, 'best': 0.9005395970720224},\n",
       " {'gen': 95, 'nevals': 100, 'best': 0.9005395970720224},\n",
       " {'gen': 96, 'nevals': 100, 'best': 0.9120594895824893},\n",
       " {'gen': 97, 'nevals': 100, 'best': 0.9120594895824893},\n",
       " {'gen': 98, 'nevals': 100, 'best': 0.9120594895824893},\n",
       " {'gen': 99, 'nevals': 100, 'best': 0.9120594895824893},\n",
       " {'gen': 100, 'nevals': 100, 'best': 0.9120594895824893}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_logbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 30\u001b[0m\n\u001b[1;32m     23\u001b[0m         individual[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(rng\u001b[38;5;241m.\u001b[39mchoice(a\u001b[38;5;241m=\u001b[39mcondition, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m individual_class(individual)\n\u001b[1;32m     27\u001b[0m toolbox\u001b[38;5;241m.\u001b[39mregister(alias \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindividual\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m                  function \u001b[38;5;241m=\u001b[39m generate_individual,\n\u001b[1;32m     29\u001b[0m                  individual_class \u001b[38;5;241m=\u001b[39m creator\u001b[38;5;241m.\u001b[39mindividual,\n\u001b[0;32m---> 30\u001b[0m                  grid \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241m.\u001b[39mgrid)\n\u001b[1;32m     32\u001b[0m toolbox\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopulation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     33\u001b[0m                  tools\u001b[38;5;241m.\u001b[39minitRepeat,\n\u001b[1;32m     34\u001b[0m                  \u001b[38;5;28mlist\u001b[39m,\n\u001b[1;32m     35\u001b[0m                  toolbox\u001b[38;5;241m.\u001b[39mindividual)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid' is not defined"
     ]
    }
   ],
   "source": [
    "creator.create(name = 'fitness',\n",
    "               base = base.Fitness,\n",
    "               weights = (1.0, -1.0,)) # Set to maximize Spearman correlation of MA_activator and cActivator, and minimize MA_inhibitor and cInhibitor\n",
    "\n",
    "creator.create(name = 'individual',\n",
    "               base = np.ndarray,\n",
    "               shape = (274,), # Number of conditions\n",
    "               dtype = np.dtype([('act', float), ('inh', float)]), # Custom dtype\n",
    "               fitness = creator.fitness)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "def generate_individual(individual_class: type, grid: pd.Series):\n",
    "    '''\n",
    "    Randomly pick tuples from each condition's grid to create an individual\n",
    "    \n",
    "    :param type individual_class: Class that the individual will inherit from\n",
    "    :param pd.Series grid: Contains the parameter grids for each condition\n",
    "    '''\n",
    "    individual = np.empty(shape=individual_class.shape, dtype=individual_class.dtype)\n",
    "\n",
    "    for i, condition in enumerate(grid):\n",
    "        individual[i] = tuple(rng.choice(a=condition, size=1, replace=False)[0])\n",
    "        \n",
    "    return individual_class(individual)\n",
    "\n",
    "toolbox.register(alias = 'individual',\n",
    "                 function = generate_individual,\n",
    "                 individual_class = creator.individual,\n",
    "                 grid = grid.grid)\n",
    "\n",
    "toolbox.register('population',\n",
    "                 tools.initRepeat,\n",
    "                 list,\n",
    "                 toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "MA_df = data.iloc[:,0:2]\n",
    "\n",
    "def spearman_objective(individual: object, MA_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculate spearman coefficient between cAct/cInh and MA_act/MA_inh\n",
    "    \n",
    "    :param object individual: DEAP individual\n",
    "    :param pd.DataFrame MA_df: Df with columns = ['MA_activator','MA_inhibitor']\n",
    "    \"\"\"\n",
    "\n",
    "    # Create arrays with the ordered condition parameters\n",
    "    MA_activator = MA_df.loc[:,'MA_activator']\n",
    "    MA_inhibitor = MA_df.loc[:,'MA_inhibitor']\n",
    "\n",
    "    ind_activator = individual['act']\n",
    "    ind_inhibitor = individual['inh']\n",
    "    \n",
    "    # Calculate the spearman rank coefficient\n",
    "    activator_spearman = spearmanr(MA_activator, ind_activator)[0]\n",
    "    inhibitor_spearman = spearmanr(MA_inhibitor, ind_inhibitor)[0]\n",
    "    \n",
    "    return activator_spearman, inhibitor_spearman,\n",
    "\n",
    "toolbox.register(alias = 'evaluate',\n",
    "                function = spearman_objective,\n",
    "                MA_df = MA_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"select\", tools.selNSGA2, nd='log') # I've been using selNSGA2 since it seems to run faster\n",
    "#toolbox.register(\"select\", tools.selSPEA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutation\n",
    "def mutate(individual: object, prob: float, grid: pd.Series):\n",
    "    # Iterate over all conditions if an individual is selected to mutate\n",
    "    for i, _ in enumerate(individual):\n",
    "        if rng.random() < prob:\n",
    "            # Select a new set of parameters for a condition from the grid\n",
    "            # Requires the \"grid\" to be in a specific location of the dataframe\n",
    "            individual[i] = tuple(rng.choice(a=grid.iloc[i], size=1, replace=False)[0])\n",
    "\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crossover\n",
    "def crossover(ind_one: object, ind_two: object, prob: float):\n",
    "    # Individuals are already deep-copied before going into this function\n",
    "    for i, _ in enumerate(ind_one):\n",
    "        if rng.random() < prob:\n",
    "            # Use copies to avoid modifying the np.array in place\n",
    "            ind_one[i], ind_two[i] = ind_two[i].copy(), ind_one[i].copy()\n",
    "\n",
    "    return ind_one, ind_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = tools.Statistics(key=lambda ind: np.subtract(ind.fitness.values[0],ind.fitness.values[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_individual(population: list):\n",
    "    \"\"\"\n",
    "    Returns a list containing the total scores for each individual and a list \n",
    "    containining the np.argsort indices for the ascending sorted scores\n",
    "\n",
    "    :param list population: List of individuals with fitness scores\n",
    "    \"\"\"\n",
    "    a, b = zip(*[population[i].fitness.values for i in range(len(population))])\n",
    "    total_scores = np.subtract(a,b) # Since objective weights are (1.0, -1.0)\n",
    "    sorted_index = np.argsort(total_scores)\n",
    "\n",
    "    return total_scores, sorted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied directly from DEAP, updated to use np.random\n",
    "def var_or(population, toolbox, lambda_, cxpb, mutpb):\n",
    "    r\"\"\"Part of an evolutionary algorithm applying only the variation part\n",
    "    (crossover, mutation **or** reproduction). The modified individuals have\n",
    "    their fitness invalidated. The individuals are cloned so returned\n",
    "    population is independent of the input population.\n",
    "\n",
    "    :param population: A list of individuals to vary.\n",
    "    :param toolbox: A :class:`~deap.base.Toolbox` that contains the evolution\n",
    "                    operators.\n",
    "    :param lambda\\_: The number of children to produce\n",
    "    :param cxpb: The probability of mating two individuals.\n",
    "    :param mutpb: The probability of mutating an individual.\n",
    "    :returns: The final population.\n",
    "\n",
    "    The variation goes as follow. On each of the *lambda_* iteration, it\n",
    "    selects one of the three operations; crossover, mutation or reproduction.\n",
    "    In the case of a crossover, two individuals are selected at random from\n",
    "    the parental population :math:`P_\\mathrm{p}`, those individuals are cloned\n",
    "    using the :meth:`toolbox.clone` method and then mated using the\n",
    "    :meth:`toolbox.mate` method. Only the first child is appended to the\n",
    "    offspring population :math:`P_\\mathrm{o}`, the second child is discarded.\n",
    "    In the case of a mutation, one individual is selected at random from\n",
    "    :math:`P_\\mathrm{p}`, it is cloned and then mutated using using the\n",
    "    :meth:`toolbox.mutate` method. The resulting mutant is appended to\n",
    "    :math:`P_\\mathrm{o}`. In the case of a reproduction, one individual is\n",
    "    selected at random from :math:`P_\\mathrm{p}`, cloned and appended to\n",
    "    :math:`P_\\mathrm{o}`.\n",
    "\n",
    "    This variation is named *Or* because an offspring will never result from\n",
    "    both operations crossover and mutation. The sum of both probabilities\n",
    "    shall be in :math:`[0, 1]`, the reproduction probability is\n",
    "    1 - *cxpb* - *mutpb*.\n",
    "    \"\"\"\n",
    "\n",
    "    assert (cxpb + mutpb) <= 1.0, (\n",
    "        \"The sum of the crossover and mutation probabilities must be smaller \"\n",
    "        \"or equal to 1.0.\")\n",
    "\n",
    "    offspring = []\n",
    "    for _ in range(lambda_):\n",
    "        op_choice = rng.random()\n",
    "        if op_choice < cxpb:\n",
    "            # Apply crossover\n",
    "            # Use rng.choice with arange to get a random integer and copy that individual, rather than generate an np.array and create an individual from that\n",
    "            ind1, ind2 = [toolbox.clone(population[i]) for i in rng.choice(a=np.arange(start=0, stop=len(population), step=1), size=2, replace=False)]\n",
    "            ind1, ind2 = toolbox.mate(ind1, ind2)\n",
    "            del ind1.fitness.values\n",
    "            offspring.append(ind1) # We currently only take one of the crossover indidivuals\n",
    "        elif op_choice < cxpb + mutpb:\n",
    "            # Apply mutation\n",
    "            ind = toolbox.clone(population[rng.choice(a=np.arange(start=0, stop=len(population), step=1), size=1, replace=False)[0]])\n",
    "            ind = toolbox.mutate(ind)\n",
    "            del ind.fitness.values\n",
    "            offspring.append(ind)\n",
    "        else:\n",
    "            # Apply reproduction\n",
    "            ind = toolbox.clone(population[rng.choice(a=np.arange(start=0, stop=len(population), step=1), size=1, replace=False)[0]])\n",
    "            offspring.append(ind)\n",
    "\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_plus_lambda(population = list,\n",
    "                   toolbox = base.Toolbox(),\n",
    "                   mu = int,\n",
    "                   lambda_ = int,\n",
    "                   cxpb = float,\n",
    "                   mutpb = float,\n",
    "                   n_gen = int,\n",
    "                   n_iter = int,\n",
    "                   grid = pd.Series,\n",
    "                   stats = None,\n",
    "                   hall_of_fame = None,\n",
    "                   verbose = __debug__):\n",
    "    \"\"\"\n",
    "    Modified DEAP mu+lambda evolutionary algorithm using varOr\n",
    "\n",
    "    :param list population: List of individuals to serve as the starting population\n",
    "    :param base.Toolbox() toolbox: DEAP class containing evolution operators\n",
    "    :param int mu: Number of individuals to select for the next generation\n",
    "    :param int lambda_: Number of children to produce at each generation\n",
    "    :param float cxpb: Probability that an offspring is produced by crossover\n",
    "    :param float mutpb: Probability that an offspring is produced by mutation\n",
    "    :param int n_gen: Number of generations to run\n",
    "    :param int n_iter: Greedy offspring population size\n",
    "    :param pd.Series grid: Series containing grids for each condition\n",
    "    :param stats: DEAP class containing the types of statistics to record in the logbook\n",
    "    :param halloffame: DEAP class containing the best individuals evaluated\n",
    "    :param verbose: Whether or not to print statistics for each generation\n",
    "    :returns list pop: Final population\n",
    "    :returns logbook: DEAP class containing stats for every generation\n",
    "\n",
    "    evaluate(population)\n",
    "    for g in range(ngen):\n",
    "        offspring = varOr(population, toolbox, lamda_, cxpb, mutpb)\n",
    "        evaluate(offspring)\n",
    "        gradient_offspring = create_gradient_offspring(hof[0], toolbox)\n",
    "        evaluate(gradient_offspring)\n",
    "        population = select(population+offspring+gradient_offspring, mu)\n",
    "    \"\"\"\n",
    "\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals', 'best'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if hall_of_fame is not None:\n",
    "        hall_of_fame.update(population)\n",
    "\n",
    "    total_scores, sorted_index = best_individual(population)\n",
    "\n",
    "    record = stats.compile(population) if stats is not None else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), best=total_scores[sorted_index[-1]], **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, n_gen + 1):\n",
    "        # Vary the population\n",
    "        offspring = var_or(population, toolbox, lambda_, cxpb, mutpb)\n",
    "\n",
    "        # Greedy offspring\n",
    "        if gen % 100 == 0:\n",
    "            greedy_offspring, _ = create_greedy_offspring(population[sorted_index[-1]], n_iter, grid)\n",
    "            offspring = offspring+greedy_offspring\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        # NOTE: I feel like HoF should update after the next population is created? That way we only have to compare max mu individuals to the HoF?\n",
    "        if hall_of_fame is not None:\n",
    "            hall_of_fame.update(offspring)\n",
    "\n",
    "        # Manually ensure elitism\n",
    "        population = population + offspring\n",
    "        _, temp_sorted = best_individual(population)\n",
    "        hof_individual = population[temp_sorted[-1]]\n",
    "\n",
    "        # Select the next generation population\n",
    "        population[:] = toolbox.select(population, mu)\n",
    "        population.append(hof_individual)\n",
    "\n",
    "        # Update the statistics with the new population\n",
    "        total_scores, sorted_index = best_individual(population)\n",
    "\n",
    "        record = stats.compile(population) if stats is not None else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), best=total_scores[sorted_index[-1]], **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECOND DRAFT\n",
    "# Rather than deal with having to look up where the tuple is, I think my next step should be to make the first n tuples correspond to the locations of the n parameters that are set in each tuple\n",
    "# For this case, that would mean that the first number would correspond to the position of the cAct value in the list\n",
    "def create_greedy_offspring(base_individual: object,\n",
    "                            n_iterations: int,\n",
    "                            grid: pd.Series):\n",
    "    \"\"\"\n",
    "    Returns a population of modified individuals that have different parameters\n",
    "    for one condition\n",
    "\n",
    "    :param object base_individual: Individual to copy parameters from\n",
    "    :param int n_iterations: How many random copies should be created\n",
    "    :param pd.Series grid: Series containing grids for each condition\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create population to hold the individuals we are trying out\n",
    "    population = toolbox.population(n=0)\n",
    "\n",
    "    # Create a pd.Series to hold position of each condition's parameter tuple\n",
    "    position = pd.Series(index = grid.index, dtype = 'Int64')\n",
    "\n",
    "    for i, (ind_act, ind_inh) in enumerate(base_individual):\n",
    "        # Iterate through the grid parameters for each condition\n",
    "        for ii, (grid_act, grid_inh) in enumerate(grid[i]):\n",
    "            if (ind_act, ind_inh) == (grid_act, grid_inh):\n",
    "                position[i] = ii\n",
    "\n",
    "    # Record the number of steps needed for each condition at each iteration\n",
    "    steps = pd.DataFrame(index=grid.index, columns=range(n_iterations))\n",
    "\n",
    "    # Shuffle the order of the conditions and run it many times\n",
    "    for i in range(n_iterations):\n",
    "        # Copy the grid and position series and shuffle them\n",
    "        temp_grid = grid.sample(frac=1, replace=False, random_state=i)\n",
    "        temp_position = position.reindex(temp_grid.index)\n",
    "\n",
    "        # Create the iteration's temporary individual\n",
    "        base_score = np.subtract(base_individual.fitness.values[0], base_individual.fitness.values[1])\n",
    "        temp_individual = toolbox.clone(base_individual)\n",
    "\n",
    "        # Baseline\n",
    "        old_l_score = base_score\n",
    "        old_r_score = base_score\n",
    "\n",
    "        # Loop over the shuffled conditions\n",
    "        for cond in temp_grid.index:\n",
    "            # Create the condition's temporary individuals\n",
    "            l_individual = toolbox.clone(temp_individual)\n",
    "            r_individual = toolbox.clone(temp_individual)\n",
    "\n",
    "            # Identify where in the individual the condition's parameters are\n",
    "            cond_loc = grid.index.get_loc(cond)\n",
    "\n",
    "            # Determine where in the grid the condition's parameters are\n",
    "            l_position = int(temp_position[cond]-1)\n",
    "            r_position = int(temp_position[cond]+1)\n",
    "\n",
    "            # Search the \"left\" side\n",
    "            while l_position > -1:\n",
    "                # Modify the individual, evaluate, and score\n",
    "                l_individual[cond_loc] = temp_grid[cond][l_position]\n",
    "                l_individual.fitness.values = toolbox.evaluate(l_individual)\n",
    "                new_l_score = np.subtract(l_individual.fitness.values[0],l_individual.fitness.values[1])\n",
    "\n",
    "                # Compare the score against the best individual\n",
    "                if new_l_score > old_l_score: # Check the next \"left\" position\n",
    "                    l_position -= 1\n",
    "                else: # Roll the individual back one step\n",
    "                    l_position += 1\n",
    "                    l_individual[cond_loc] = temp_grid[cond][l_position]\n",
    "                    l_individual.fitness.values = toolbox.evaluate(l_individual)\n",
    "                    old_l_score = np.subtract(l_individual.fitness.values[0],l_individual.fitness.values[1])\n",
    "                    break\n",
    "\n",
    "            # Search the \"right\" side\n",
    "            while r_position < len(temp_grid[cond]):\n",
    "                # Modify the individual, evaluate, and score\n",
    "                r_individual[cond_loc] = temp_grid[cond][r_position]\n",
    "                r_individual.fitness.values = toolbox.evaluate(r_individual)\n",
    "                new_r_score = np.subtract(r_individual.fitness.values[0],r_individual.fitness.values[1])\n",
    "\n",
    "                # Compare the score against the best individual\n",
    "                if new_r_score > old_r_score: # Check the next \"left\" position\n",
    "                    r_position += 1\n",
    "                else: # Roll the individual back one step\n",
    "                    r_position -= 1\n",
    "                    r_individual[cond_loc] = temp_grid[cond][r_position]\n",
    "                    r_individual.fitness.values = toolbox.evaluate(r_individual)\n",
    "                    old_r_score = np.subtract(r_individual.fitness.values[0],r_individual.fitness.values[1])\n",
    "                    break\n",
    "\n",
    "            # Compare r_individual and l_individual, use best\n",
    "            if old_r_score > old_l_score:\n",
    "                temp_individual = r_individual\n",
    "                new_position = r_position\n",
    "            else:\n",
    "                temp_individual = l_individual\n",
    "                new_position = l_position\n",
    "            temp_individual.fitness.values = toolbox.evaluate(temp_individual)\n",
    "\n",
    "            # Determine steps from original positions\n",
    "            steps.loc[cond, i] = abs(temp_position[cond]-new_position)\n",
    "            \n",
    "        # Add individual to population\n",
    "        population.append(temp_individual)\n",
    "    \n",
    "    return population, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_greedy(base_individual: object,\n",
    "                    n_iterations: int,\n",
    "                    grid: pd.Series):\n",
    "    \"\"\"\n",
    "    Returns a population of modified individuals that have different parameters\n",
    "    for one condition\n",
    "\n",
    "    :param object base_individual: Individual to copy parameters from\n",
    "    :param int n_iterations: How many random copies should be created\n",
    "    :param pd.Series grid: Series containing grids for each condition\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create population to hold the individuals we are trying out\n",
    "    population = toolbox.population(n=0)\n",
    "\n",
    "    # Create a pd.Series to hold position of each condition's parameter tuple\n",
    "    position = pd.Series(index = grid.index, dtype = 'Int64')\n",
    "\n",
    "    for i, (ind_act, ind_inh) in enumerate(base_individual):\n",
    "        # Iterate through the grid parameters for each condition\n",
    "        for ii, (grid_act, grid_inh) in enumerate(grid[i]):\n",
    "            if (ind_act, ind_inh) == (grid_act, grid_inh):\n",
    "                position[i] = ii\n",
    "\n",
    "    # Record the number of steps needed for each condition at each iteration\n",
    "    steps = pd.DataFrame(index=grid.index, columns=range(n_iterations))\n",
    "    max_steps = 30\n",
    "\n",
    "    # Shuffle the order of the conditions and run it many times\n",
    "    for i in range(n_iterations):\n",
    "        # Create the iteration's temporary individual\n",
    "        base_score = np.subtract(base_individual.fitness.values[0], base_individual.fitness.values[1])\n",
    "        temp_individual = toolbox.clone(base_individual)\n",
    "\n",
    "        # Baseline score\n",
    "        old_l_score = base_score\n",
    "        old_r_score = base_score\n",
    "\n",
    "        # Create a copy of the grid and position series as new objects\n",
    "        temp_position = position.copy(deep=True)\n",
    "\n",
    "        for ii in range(100):\n",
    "            # Copy the grid and position series and shuffle them\n",
    "            temp_grid = grid.sample(frac=1, replace=False, random_state=i+ii) # What's the best way to set the random state?\n",
    "\n",
    "            # Loop over the shuffled conditions\n",
    "            for cond in temp_grid.index:\n",
    "                # Create the condition's temporary individuals\n",
    "                l_individual = toolbox.clone(temp_individual)\n",
    "                r_individual = toolbox.clone(temp_individual)\n",
    "\n",
    "                # Identify where in the individual the condition's parameters are\n",
    "                cond_loc = int(grid.index.get_loc(cond))\n",
    "\n",
    "                if int(temp_position.loc[cond]) == 0:\n",
    "                    l_position = 0\n",
    "                else:\n",
    "                    l_position = int(temp_position.loc[cond]-1)\n",
    "                    l_steps = 1\n",
    "\n",
    "                    # Search the \"left\" side\n",
    "                    while l_position > -1:\n",
    "                    # Modify the individual, evaluate, and score\n",
    "                        l_individual[cond_loc] = temp_grid.loc[cond][l_position]\n",
    "                        l_individual.fitness.values = toolbox.evaluate(l_individual)\n",
    "                        new_l_score = np.subtract(l_individual.fitness.values[0],l_individual.fitness.values[1])\n",
    "\n",
    "                        # Compare the score against the best individual\n",
    "                        if new_l_score > old_l_score:\n",
    "                            # Continue if not at the end of the grid\n",
    "                            if l_position == 0 or l_steps == max_steps:\n",
    "                                old_l_score = new_l_score\n",
    "                                break\n",
    "                            else:\n",
    "                                l_position -= 1\n",
    "                                l_steps += 1\n",
    "                        else: # Roll the individual back one step\n",
    "                            l_position += 1\n",
    "                            #print(i, ii, cond, l_position, len(temp_grid.loc[cond]))\n",
    "                            l_individual[cond_loc] = temp_grid.loc[cond][l_position]\n",
    "                            l_individual.fitness.values = toolbox.evaluate(l_individual)\n",
    "                            old_l_score = np.subtract(l_individual.fitness.values[0],l_individual.fitness.values[1])\n",
    "                            break\n",
    "\n",
    "                if int(temp_position.loc[cond])+1 == len(temp_grid.loc[cond]):\n",
    "                    # This if statement is needed to prevent it from adding one, realizing it is out of bounds, performing better than the left side, and updating to a grid location that is out of bounds\n",
    "                    r_position = int(temp_position.loc[cond])\n",
    "                else:\n",
    "                    r_position = int(temp_position.loc[cond]+1)\n",
    "                    r_steps = 1\n",
    "                    \n",
    "                    # Search the \"right\" side\n",
    "                    while r_position < len(temp_grid.loc[cond]):\n",
    "                        # Modify the individual, evaluate, and score\n",
    "                        r_individual[cond_loc] = temp_grid.loc[cond][r_position]\n",
    "                        r_individual.fitness.values = toolbox.evaluate(r_individual)\n",
    "                        new_r_score = np.subtract(r_individual.fitness.values[0],r_individual.fitness.values[1])\n",
    "\n",
    "                        # Compare the score against the best individual\n",
    "                        if new_r_score > old_r_score:\n",
    "                            # Continue if not at the end of the grid\n",
    "                            if r_position+1 == len(temp_grid.loc[cond]) or r_steps == max_steps:\n",
    "                                old_r_score = new_r_score\n",
    "                                break\n",
    "                            else:\n",
    "                                r_position += 1\n",
    "                                r_steps += 1\n",
    "                        else: # Roll the individual back one step\n",
    "                            r_position -= 1\n",
    "                            r_individual[cond_loc] = temp_grid.loc[cond][r_position]\n",
    "                            r_individual.fitness.values = toolbox.evaluate(r_individual)\n",
    "                            old_r_score = np.subtract(r_individual.fitness.values[0],r_individual.fitness.values[1])\n",
    "                            break\n",
    "\n",
    "                # Compare r_individual and l_individual, use best, update the positions for the next round\n",
    "                if old_r_score > old_l_score:\n",
    "                    temp_individual = r_individual\n",
    "                    temp_position.loc[cond] = r_position\n",
    "                else:\n",
    "                    temp_individual = l_individual\n",
    "                    temp_position.loc[cond] = l_position\n",
    "                temp_individual.fitness.values = toolbox.evaluate(temp_individual)\n",
    "            \n",
    "        # Add individual to population\n",
    "        population.append(temp_individual)\n",
    "    \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_greedy(population: list, grid: pd.Series):\n",
    "    # Create a pd.Series to hold position of each condition's parameter tuple\n",
    "    position = pd.DataFrame(index=grid.index, columns=range(len(population)), dtype='Int64')\n",
    "\n",
    "    for i, ind in enumerate(population):\n",
    "        for ii, (ind_act, ind_inh) in enumerate(ind):\n",
    "            # Iterate through the grid parameters for each condition\n",
    "            for iii, (grid_act, grid_inh) in enumerate(grid[ii]):\n",
    "                if (ind_act, ind_inh) == (grid_act, grid_inh):\n",
    "                    position.iloc[ii, i] = iii\n",
    "\n",
    "    position['rounded_mean'] = position.mean(axis=1).round()\n",
    "    position['rounded_median'] = position.median(axis=1).round()\n",
    "\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# NOTE: Using np.ndarray individuals requires a different method to compare individuals\n",
    "nind = 100\n",
    "mu = 100\n",
    "lambda_ = 100\n",
    "n_iter = 0\n",
    "path = r'/home/gchhughes/Dropbox (UCSD SBRG)/gchughes@ucsd.edu’s files/regulonML_hyperparameter_optimization/'\n",
    "\n",
    "for n_gen in [100, 1000, 10000]:\n",
    "    for (cxpb, mutpb) in [(0,1), (0.1,0.9), (0.2,0.8), (0.3,0.7), (0.4,0.6), (0.5,0.5), (0.6,0.4), (0.7,0.3), (0.8,0.2), (0.9,0.1), (1,0)]:\n",
    "        for cx_prob in [0.2, 0.4, 0.6, 0.8, 1]:\n",
    "            toolbox.register(alias = \"mate\", function = crossover, prob = cx_prob,)\n",
    "\n",
    "            for mt_prob in [0.2, 0.4, 0.6, 0.8, 1]:\n",
    "                toolbox.register('mutate', function = mutate, prob = mt_prob, grid = grid.grid)\n",
    "\n",
    "\n",
    "                # Set reproducible random seed\n",
    "                seed = 42\n",
    "                rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "                # Time how long the GA takes\n",
    "                start_time = time.time()\n",
    "                pop, logbook = mu_plus_lambda(toolbox.population(n=nind), toolbox, mu=mu, lambda_=lambda_, cxpb=cxpb, mutpb=mutpb, n_gen=n_gen, n_iter = n_iter, grid = grid.grid, stats=stats, verbose=True)\n",
    "                end_time = time.time()\n",
    "                elapsed_time = round(end_time-start_time, 2)\n",
    "    \n",
    "                # Save the parameter grid, final population, logbook, and time to a .pkl\n",
    "                filename = r'__seed_'+str(seed)+'__gen_'+str(n_gen)+'__pop_'+str(nind)+'__mu_'+str(mu)+'__lambda_'+str(lambda_)+'__cxind_'+str(cxpb)+'__cxgene_'+str(cx_prob)+'__mtind_'+str(mutpb)+'__mtgene_'+str(mt_prob)+'.pkl'\n",
    "                print('Time: '+str(elapsed_time)+filename)\n",
    "\n",
    "                with open(file=path+filename, mode='wb') as file:\n",
    "                    pickle.dump(obj=[grid, pop, logbook, elapsed_time], file=file)\n",
    "                # Can access them from a separate device while they are all still running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sym-seq-ml",
   "language": "python",
   "name": "sym-seq-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
