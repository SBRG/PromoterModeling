{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4af779",
   "metadata": {
    "code_folding": [
     31
    ]
   },
   "outputs": [],
   "source": [
    "# imports and loadings\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../functions/')\n",
    "import mRNA_ratios as mr\n",
    "import create_data_for_single_gene as cdg\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# load in settings flags\n",
    "settings_df = pd.read_csv('../options/settings.csv', index_col = 0)\n",
    "flags_filepath = settings_df.loc['gene_flags_filepath']['Setting']\n",
    "TF_flags_filepath = settings_df.loc['TF_flags_filepath']['Setting']\n",
    "flags_df = pd.read_csv(flags_filepath)\n",
    "flags_df = flags_df[flags_df['include'] == True]\n",
    "genes = flags_df.index.to_list()\n",
    "\n",
    "# below are the default flags used if nothing is pre-set\n",
    "t_half_life_deg = 300\n",
    "stable_flags = { # these do not change gene by gene\n",
    "    # overall\n",
    "    'only_create_ratios' : True,\n",
    "    'only_check_KdRNAPAct' : True, # if True, quit out of code after generating KdRNAPAct, done to see if it is generating valid values through sanity check plots\n",
    "    'save_results' : True, # saves resulting figures and cAct/cInh values of the previous run to the save_results_run folder\n",
    "    'include_Amy_samples' : True, # append on Amy's stationary phase samples to analysis\n",
    "    'remove_outliers' : True, # removes samples that do not correlate well with others, see ../data_cleaning/1_locate_outliers_to_drop.ipynb\n",
    "    'case' : False, # only used for remove_outliers right now\n",
    "    'drop_basal_conds' : False,\n",
    "    \n",
    "    # KdRNAPAct optimization\n",
    "    'KdRNAPAct_sanity' : True, # if True, return sanity plots from this optimization\n",
    "    # GAMs\n",
    "    'supress_output' : False,\n",
    "    'use_greedy' : True, # use the greedy algo values (if False, uses the results of the GA)\n",
    "    'run_on_all' : False, # run on all genes that are in the saved output folder\n",
    "    'limit_samples' : genes, #['b1101', 'b1817', 'b1818', 'b1819'], # if run_on_all is False, limit to these samples (or which of them are available)\n",
    "    'delete_old' : True,\n",
    "    'run_seperate' : False, # run cActivator and cInhibitor solvers seperately\n",
    "    \n",
    "    # input constants for GAMs (all get logged inside GAMs so pass in un-logged)\n",
    "    'act_TF_conc_lo' : 1e-10,\n",
    "    'act_TF_conc_up' : 1e-5,\n",
    "    'act_Kd_lo' : 1e-10,\n",
    "    'act_Kd_up' : 1e-6,\n",
    "    'inh_TF_conc_lo' : 1e-10,\n",
    "    'inh_TF_conc_up' : 1e-5,\n",
    "    'inh_Kd_lo' : 1e-10,\n",
    "    'inh_Kd_up' : 1e-6,\n",
    "    # objective function weightings\n",
    "    'weight_act_obj1' : 1,\n",
    "    'weight_inh_obj1' : 1,\n",
    "    'weight_act_obj2' : 0,\n",
    "    'weight_inh_obj2' : 0,\n",
    "    'weight_mRNA_match' : .1,\n",
    "    'weight_act_corr' : 0.00000000000000001,\n",
    "    'weight_inh_corr' : 0.00000000000000001,\n",
    "    \n",
    "    \n",
    "    # misc\n",
    "    'eq_str' : 'Eq(mRNARatio,((cActivator*KdRNAP + KdRNAPAct)*(KdRNAP + RNAP + \\\n",
    "            KeqOpening*RNAP))/((1 + cActivator + cInhibitor)*KdRNAP*KdRNAPAct + \\\n",
    "            cActivator*KdRNAP*(1 + KeqOpening)*RNAP + KdRNAPAct*(1 + \\\n",
    "            KeqOpening)*RNAP))',\n",
    "    \n",
    "    # cell_constants'\n",
    "    'cell_constants_RNAP': 10**-6,\n",
    "    'cell_constants_mRNA_total': 1800, # Total mRNA/cell from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3554401\n",
    "    'cell_constants_cell_volume': 10**-15, # Liters from https://bionumbers.hms.harvard.edu/bionumber.aspx?id=100004&ver=19\n",
    "    'cell_constants_kDeg': np.log(2)/t_half_life_deg, # Rate of degradation\n",
    "    'cell_constants_promoterConcVal': 10**-9, # Promoter concentration\n",
    "    'cell_constants_u': 1/3600, # Growth rate\n",
    "}\n",
    "\n",
    "# fixing up saved_flags to work for new values\n",
    "for index, row in flags_df.iterrows():\n",
    "    if type(row['basal_conditions']) == float and math.isnan(row['basal_conditions']):\n",
    "        flags_df.at[index, 'basal_conditions'] = \"[\\'p1k_00001\\', \\'p1k_00002\\']\"\n",
    "    if type(row['target_range']) == float and math.isnan(row['target_range']):\n",
    "        flags_df.at[index, 'target_range'] = \"[-1, 3]\"\n",
    "    if type(row['cActivator']) == float and math.isnan(row['cActivator']):\n",
    "        flags_df.at[index, 'cActivator'] = \"[-4, 2]\"\n",
    "    if type(row['cInhibitor']) == float and math.isnan(row['cInhibitor']):\n",
    "        flags_df.at[index, 'cInhibitor'] = \"[-4, 2]\"\n",
    "    flags_df.at[index, 'force_rerun'] = True\n",
    "    flags_df.at[index, 'basal_or_hard_val'] = 'basal'\n",
    "\n",
    "# function to enable display of pickled figures\n",
    "def show_figure(fig):\n",
    "\n",
    "    # create a dummy figure and use its\n",
    "    # manager to display \"fig\"\n",
    "\n",
    "    dummy = plt.figure()\n",
    "    new_manager = dummy.canvas.manager\n",
    "    new_manager.canvas.figure = fig\n",
    "    fig.set_canvas(new_manager.canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144acf1e",
   "metadata": {},
   "source": [
    "# set basal conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef13b2eb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load log tpm\n",
    "# loading\n",
    "log_tpm_df = pd.read_csv('../data/external/imodulon_info/log_tpm.csv', index_col = 0)\n",
    "starve_log_tpm = pd.read_csv('../data/external/validation_data_sets/stationary_phase/cleaned_log_tpm_qc.csv', index_col = 0)\n",
    "to_blank_inds = list(set(log_tpm_df.index) - set(starve_log_tpm.index))\n",
    "# need to create zero rows for missing values\n",
    "zeros_data = {col : 0 for col in starve_log_tpm.columns}\n",
    "zeros_df = pd.DataFrame(zeros_data, index = to_blank_inds)\n",
    "starve_log_tpm = pd.concat([starve_log_tpm, zeros_df])\n",
    "starve_log_tpm = starve_log_tpm.loc[log_tpm_df.index]\n",
    "log_tpm_df = pd.concat([starve_log_tpm, log_tpm_df], axis = 1)\n",
    "\n",
    "input_df = pd.read_csv(flags_filepath, index_col = 0)\n",
    "\n",
    "# loop through each case, find the best basal\n",
    "act_inh_combos = list(set([(row['act_iM'], row['inh_iM']) for _, row in input_df.iterrows()]))\n",
    "case_to_basal = {}\n",
    "for act, inh in act_inh_combos:\n",
    "    result_df = input_df[(input_df['act_iM'] == act) | (pd.isna(input_df['act_iM']) & pd.isna(act))]\n",
    "    result_df = result_df[(result_df['inh_iM'] == inh) | (pd.isna(result_df['inh_iM']) & pd.isna(inh))]\n",
    "    genes = result_df.index.to_list()\n",
    "\n",
    "    # scale and normalize it\n",
    "    bby = log_tpm_df.loc[genes].copy()\n",
    "    to_drop = []\n",
    "    for col in bby.columns:\n",
    "        if (bby[col] == 0).any():\n",
    "            to_drop.append(col)\n",
    "    bby = bby.drop(to_drop, axis=1)\n",
    "    df = 2**bby.T\n",
    "    normalized_df=(df-df.mean())/df.std()\n",
    "    normalized_df = normalized_df\n",
    "    normalized_df['avg_exp'] = normalized_df.mean(axis = 1)\n",
    "    normalized_df['abs_avg_exp'] = abs(normalized_df['avg_exp'])\n",
    "    \n",
    "    # check if activator, inhibitor, or both\n",
    "    if pd.isna(act) and not pd.isna(inh):\n",
    "        # inhibitor case, pick the top expressed example to be basal\n",
    "        basal = [normalized_df.sort_values(by = 'avg_exp').index[-1]]\n",
    "    elif pd.isna(inh) and not pd.isna(act):\n",
    "        # activator case, pick the least expressed example to be basal\n",
    "        basal = [normalized_df.sort_values(by = 'avg_exp').index[0]]\n",
    "    elif not pd.isna(inh) and not pd.isna(act):\n",
    "        # both case, pick the most average expressed example to be basal\n",
    "        basal = [normalized_df.sort_values(by = 'abs_avg_exp').index[0]]\n",
    "    case_to_basal.update({(act, inh) : [str(basal[0])]})\n",
    "\n",
    "# now add the new values to the dataframe\n",
    "basals = []\n",
    "for _, row in input_df.iterrows():\n",
    "    case = (row['act_iM'], row['inh_iM'])\n",
    "    basals.append(case_to_basal[case])\n",
    "input_df['basal_conditions'] = basals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d400fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it off\n",
    "input_df.to_csv(flags_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3205b418",
   "metadata": {},
   "source": [
    "# manual investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b082a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load log tpm\n",
    "log_tpm_df = pd.read_csv('../data/external/imodulon_info/log_tpm.csv', index_col = 0)\n",
    "starve_log_tpm = pd.read_csv('../data/validation_data_sets/stationary_phase/cleaned_log_tpm_qc.csv', index_col = 0)\n",
    "to_blank_inds = list(set(log_tpm_df.index) - set(starve_log_tpm.index))\n",
    "# need to create zero rows for missing values\n",
    "zeros_data = {col : 0 for col in starve_log_tpm.columns}\n",
    "zeros_df = pd.DataFrame(zeros_data, index = to_blank_inds)\n",
    "starve_log_tpm = pd.concat([starve_log_tpm, zeros_df])\n",
    "starve_log_tpm = starve_log_tpm.loc[log_tpm_df.index]\n",
    "log_tpm_df = pd.concat([starve_log_tpm, log_tpm_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and normalize it\n",
    "bby = log_tpm_df.loc[genes].copy()\n",
    "to_drop = []\n",
    "for col in bby.columns:\n",
    "    if (bby[col] == 0).any():\n",
    "        to_drop.append(col)\n",
    "bby = bby.drop(to_drop, axis=1)\n",
    "df = 2**bby.T\n",
    "normalized_df=(df-df.mean())/df.std()\n",
    "normalized_df = normalized_df\n",
    "normalized_df['avg_exp'] = normalized_df.mean(axis = 1)\n",
    "normalized_df['abs_avg_exp'] = abs(normalized_df['avg_exp'])\n",
    "normalized_df.sort_values(by = 'avg_exp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
